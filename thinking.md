# Thinking1	奇异值分解SVD的原理是怎样的，都有哪些应用场景 #

答：svd可以解决在矩阵分解中，很多矩阵都是非对称的，即矩阵A不是方阵，即维度为m*n的问题，可以将矩阵A转化为对称的方阵，即A和A的转置矩阵  与   A的转置矩阵和A 是对称方阵。  所以将A和A的转置矩阵进行相乘，得到对称方阵。经转换，可得奇异值分解，A=PΛQT
P为左奇异矩阵，m*m维
Q为右奇异矩阵，n*n维
Λ对角线上的非零元素为特征值λ1, λ2, ... , λk
在推荐系统中
左奇异矩阵：User矩阵
右奇异矩阵：Item矩阵。

典型的应用场景：数据压缩（以图像压缩为代表），推荐系统也有应用。



# Thinking2	funkSVD, BiasSVD，SVD++算法之间的区别是怎样的 #

答：FunkSVD为了防止过拟合，增加正则化项
BiasSVD 加入了用户和商品的偏好
SVD++ 在BiasSVD算法基础上考虑了用户的隐式反馈


# Thinking3	矩阵分解算法在推荐系统中有哪些应用场景，存在哪些不足 #

答：奇异值分解可以对矩阵进行无损分解
可以利用SVD降维
在评分预测中使用funkSVD，根据实际评分误差进行目标最优化
在funkSVD的基础上，加入用户/商品偏好 => BiasSVD
在BiasSVD的基础上，考虑用户的隐式反馈 => SVD++

不足：因为是矩阵运算，所以只考虑了user和item特征，对于多维度的考虑不能够满足需要。



# Thinking4	假设一个小说网站，有N部小说，每部小说都有摘要描述。如何针对该网站制定基于内容的推荐系统，即用户看了某部小说后，推荐其他相关的小说。原理和步骤是怎样的 #

答：
（1）首先对每部小说的摘要进行数据清洗如标签符号，大小写等。并去掉停用词

（2）对小说摘要进行特征抽取，利用TF-IDF 得到 关键词-TFIDF值的词数对
（3）计算根据特征计算余弦相似度，并按照从大到小的顺序排列。可得与用户读的小说内容最相似的其他小说
（4）将结果放到推荐列表中对用户进行推荐。



# Thinking5	Word2Vec的应用场景有哪些 #

答：Word2Vec可以将意义相近的词将被映射到向量空间中相近的位置，不仅可以用于nlp，在大v推荐中，也可以将用户的关注顺序看作word与文章之间的关系进行运算。在商品推荐中，用户的点击顺序同理，均可用Word2Vec











